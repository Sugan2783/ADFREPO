{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "suganthidfactory"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_AGG_dept_avgsal')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "src_not_parameterized",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "tgt_not_parameterized",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "cast1"
						},
						{
							"name": "aggregate1"
						},
						{
							"name": "join1"
						},
						{
							"name": "sort1"
						},
						{
							"name": "select1"
						},
						{
							"name": "sort2"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as short,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as timestamp,",
						"          JOB_ID as string,",
						"          SALARY as integer,",
						"          COMMISSION_PCT as double,",
						"          MANAGER_ID as short,",
						"          DEPARTMENT_ID as short,",
						"          SK as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source1",
						"source1 cast(output(",
						"          EMPLOYEE_ID as integer,",
						"          SALARY as integer,",
						"          DEPARTMENT_ID as integer",
						"     ),",
						"     errors: true) ~> cast1",
						"cast1 aggregate(groupBy(DEPARTMENT_ID),",
						"     sum_SALARY = sum(SALARY),",
						"          avg_SALARY = round(avg(SALARY),2),",
						"          min_SALARY = min(SALARY),",
						"          max_SALARY = max(SALARY),",
						"          count_EMPLOYEE_ID = countDistinct(EMPLOYEE_ID),",
						"     partitionBy('hash', 1)) ~> aggregate1",
						"aggregate1, cast1 join(aggregate1@DEPARTMENT_ID == cast1@DEPARTMENT_ID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"sort2 sort(asc(DEPARTMENT_ID, true)) ~> sort1",
						"join1 select(mapColumn(",
						"          EMPLOYEE_ID,",
						"          FIRST_NAME,",
						"          LAST_NAME,",
						"          EMAIL,",
						"          PHONE_NUMBER,",
						"          HIRE_DATE,",
						"          JOB_ID,",
						"          SALARY,",
						"          COMMISSION_PCT,",
						"          MANAGER_ID,",
						"          DEPARTMENT_ID = cast1@DEPARTMENT_ID,",
						"          avg_SALARY",
						"     ),",
						"     partitionBy('hash', 1),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sort(asc(DEPARTMENT_ID, true)) ~> sort2",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string,",
						"          SK as string",
						"     ),",
						"     partitionFileNames:['tgt_departmentwise_avg_sal.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_ALL_FUNCTIONS')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Delimited_EMP_SRC",
								"type": "DatasetReference"
							},
							"name": "EMP"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Delimited_EMP_TGT",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "cast1"
						},
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as short,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as double,",
						"          COMMISSION_PCT as double,",
						"          MANAGER_ID as short,",
						"          DEPARTMENT_ID as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> EMP",
						"EMP cast(output(",
						"          EMPLOYEE_ID as integer,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as date,",
						"          JOB_ID as string,",
						"          SALARY as decimal(10,2),",
						"          COMMISSION_PCT as decimal(10,0),",
						"          MANAGER_ID as integer,",
						"          DEPARTMENT_ID as integer",
						"     ),",
						"     errors: true) ~> cast1",
						"cast1 derive(HIRE_DATE_NEW = addDays(HIRE_DATE,1),",
						"          ADD_MONTHS = addMonths(HIRE_DATE,3),",
						"          CASE = case(SALARY >= 10000,SALARY + 1000,SALARY + 5000),",
						"          CONCAT = concat(FIRST_NAME,LAST_NAME),",
						"          MD5 = md5(FIRST_NAME,LAST_NAME,EMAIL),",
						"          CURRENT_TIMESTAMP = currentTimestamp(),",
						"          DAYOFMONTH = dayOfMonth(HIRE_DATE),",
						"          DAYOFWEEK = dayOfWeek(HIRE_DATE),",
						"          GREATEROREQUAL = greaterOrEqual(length(FIRST_NAME),length(LAST_NAME)),",
						"          IIFNULL = iif(length(FIRST_NAME) > length(LAST_NAME),FIRST_NAME,LAST_NAME),",
						"          LIKE = like(FIRST_NAME,'S%'),",
						"          SPLIT = split(PHONE_NUMBER, '.'),",
						"          IIF_NULL = iifNull(COMMISSION_PCT,EMPLOYEE_ID,SALARY),",
						"          ISNULL = iif(isNull(COMMISSION_PCT),'INSERT','UPDATE'),",
						"          INSTR = instr(FIRST_NAME,'phen'),",
						"          SUBSTR = substring(EMAIL,1,instr(EMAIL,'@'))) ~> derivedColumn1",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          emp_id as string,",
						"          name as string",
						"     ),",
						"     partitionFileNames:['FUNCTIONS_EMP.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_ALTERROW')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Delimited_DEPT_SRC",
								"type": "DatasetReference"
							},
							"name": "DEPARTMENTS"
						},
						{
							"dataset": {
								"referenceName": "Delimited_TGTDEPT",
								"type": "DatasetReference"
							},
							"name": "TGTDEPARTMENTS"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Delimited_TGTDEPT",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "cast1"
						},
						{
							"name": "cast2"
						},
						{
							"name": "lookup1"
						},
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          DEPARTMENT_ID as short,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as short,",
						"          LOCATION_ID as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> DEPARTMENTS",
						"source(output(",
						"          DEPARTMENT_ID as short,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as short,",
						"          LOCATION_ID as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> TGTDEPARTMENTS",
						"DEPARTMENTS cast(output(",
						"          DEPARTMENT_ID as integer,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as integer,",
						"          LOCATION_ID as integer",
						"     ),",
						"     errors: true) ~> cast1",
						"TGTDEPARTMENTS cast(output(",
						"          DEPARTMENT_ID as integer,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as integer,",
						"          LOCATION_ID as integer",
						"     ),",
						"     errors: true) ~> cast2",
						"cast1, cast2 lookup(cast1@DEPARTMENT_ID == cast2@DEPARTMENT_ID,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookup1",
						"lookup1 alterRow(upsertIf(iif(cast2@DEPARTMENT_ID!=cast1@DEPARTMENT_ID,true(),false()))) ~> alterRow1",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          DEPARTMENT_ID as string,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as string,",
						"          LOCATION_ID as string",
						"     ),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_ALTERROW_SCD1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Delimited_EMP_SRC",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "Delimited_DEPT_SRC",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable_EMP",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "alterRow1"
						},
						{
							"name": "join1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as integer,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as decimal(10,2),",
						"          COMMISSION_PCT as decimal(10,2),",
						"          MANAGER_ID as integer,",
						"          DEPARTMENT_ID as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          DEPARTMENT_ID as integer,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as integer,",
						"          LOCATION_ID as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"select1 alterRow(upsertIf(1==1)) ~> alterRow1",
						"source1, source2 join(source1@DEPARTMENT_ID == source2@DEPARTMENT_ID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 select(mapColumn(",
						"          EMPLOYEE_ID,",
						"          FIRST_NAME,",
						"          LAST_NAME,",
						"          EMAIL,",
						"          PHONE_NUMBER,",
						"          HIRE_DATE,",
						"          JOB_ID,",
						"          SALARY,",
						"          COMMISSION_PCT,",
						"          DEPARTMENT_NAME,",
						"          LOCATION_ID,",
						"          DEPARTMENT_ID = source1@DEPARTMENT_ID",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:false,",
						"     updateable:false,",
						"     upsertable:true,",
						"     keys:['EMPLOYEE_ID'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          EMPLOYEE_ID,",
						"          FIRST_NAME,",
						"          LAST_NAME,",
						"          EMAIL,",
						"          PHONE_NUMBER,",
						"          HIRE_DATE,",
						"          JOB_ID,",
						"          SALARY,",
						"          COMMISSION_PCT,",
						"          LOCATION_ID,",
						"          DEPARTMENT_ID,",
						"          DEPARTMENT_NAME",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_AVG_DEPT_ASSIGN')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "ASSIGNMENT_DATAFLOW"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Delimited_EMP_SRC",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Delimited_EMP_TGT",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "cast1"
						},
						{
							"name": "aggregate1"
						},
						{
							"name": "join1"
						},
						{
							"name": "filter1"
						},
						{
							"name": "select1"
						},
						{
							"name": "sort1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as short,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as double,",
						"          COMMISSION_PCT as double,",
						"          MANAGER_ID as short,",
						"          DEPARTMENT_ID as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source1",
						"source1 cast(output(",
						"          EMPLOYEE_ID as integer,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as date,",
						"          JOB_ID as string,",
						"          SALARY as decimal(10,2),",
						"          COMMISSION_PCT as decimal(10,2),",
						"          MANAGER_ID as integer,",
						"          DEPARTMENT_ID as integer",
						"     ),",
						"     errors: true) ~> cast1",
						"cast1 aggregate(groupBy(DEPARTMENT_ID),",
						"     AVG_SALARY = round(avg(SALARY),2),",
						"     partitionBy('hash', 1)) ~> aggregate1",
						"aggregate1, cast1 join(aggregate1@DEPARTMENT_ID == cast1@DEPARTMENT_ID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 filter(SALARY < AVG_SALARY) ~> filter1",
						"filter1 select(mapColumn(",
						"          EMPLOYEE_ID,",
						"          FIRST_NAME,",
						"          LAST_NAME,",
						"          EMAIL,",
						"          PHONE_NUMBER,",
						"          HIRE_DATE,",
						"          JOB_ID,",
						"          SALARY,",
						"          AVG_SALARY,",
						"          COMMISSION_PCT,",
						"          MANAGER_ID,",
						"          DEPARTMENT_ID = cast1@DEPARTMENT_ID",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sort(asc(DEPARTMENT_ID, true)) ~> sort1",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          emp_id as string,",
						"          name as string",
						"     ),",
						"     partitionFileNames:['TGT_SAL_LT_AVGSAL.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_CHANNEL_REF_SCD1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "PROJECT_DATAFLOW"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "CHANNEL_REF",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AZURE_CHANNEL_REF_SCD1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						},
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          CHANNEL_ID as integer,",
						"          CHANNEL_TYPE as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 derive(STG_CREATE_DATE = currentDate()) ~> derivedColumn1",
						"derivedColumn1 alterRow(upsertIf(1==1)) ~> alterRow1",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Channel_ref_key as integer,",
						"          Channel_ID as integer,",
						"          Channel_Type as string,",
						"          STG_CREATE_DATE as date",
						"     ),",
						"     deletable:false,",
						"     insertable:false,",
						"     updateable:false,",
						"     upsertable:true,",
						"     keys:['Channel_ID'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          Channel_ID = CHANNEL_ID,",
						"          Channel_Type = CHANNEL_TYPE,",
						"          STG_CREATE_DATE",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_CONCATNAME')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText_CONCAT",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Delimited_EMP_TGT",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "cast1"
						},
						{
							"name": "window1"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "aggregate1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          col1 as string,",
						"          col2 as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source1",
						"source1 cast(output(",
						"          col1 as string,",
						"          col2 as string",
						"     ),",
						"     errors: true) ~> cast1",
						"cast1 window(asc(col1, true),",
						"     asc(col2, true),",
						"     PREV_COL1 = lag(col1)) ~> window1",
						"window1 derive(LAG_COL = iif(col1==PREV_COL1,concat(concat(col1,','),col2),col2)) ~> derivedColumn1",
						"derivedColumn1 aggregate(groupBy(col1),",
						"     count = count(col1),",
						"     partitionBy('hash', 1)) ~> aggregate1",
						"aggregate1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          emp_id as string,",
						"          name as string",
						"     ),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_CSPLIT')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "src_not_parameterized",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedText4",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "DelimitedTextsrc",
								"type": "DatasetReference"
							},
							"name": "sink2"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText3",
								"type": "DatasetReference"
							},
							"name": "sink3"
						}
					],
					"transformations": [
						{
							"name": "split1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as short,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as timestamp,",
						"          JOB_ID as string,",
						"          SALARY as integer,",
						"          COMMISSION_PCT as double,",
						"          MANAGER_ID as short,",
						"          DEPARTMENT_ID as short,",
						"          SK as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source1",
						"source1 split(DEPARTMENT_ID==50,",
						"     DEPARTMENT_ID==90,",
						"     disjoint: false) ~> split1@(DEPT50, DEPT90, DEFAULT)",
						"split1@DEPT50 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          COUNTRY_ID as string,",
						"          COUNTRY_NAME as string,",
						"          REGION_ID as string",
						"     ),",
						"     partitionFileNames:['dept_90_csplit.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1",
						"split1@DEPT90 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string,",
						"          SK as string",
						"     ),",
						"     partitionFileNames:['dept_90_csplit.CSV'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink2",
						"split1@DEFAULT sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          COUNTRY_ID as string,",
						"          COUNTRY_NAME as string,",
						"          REGION_ID as string",
						"     ),",
						"     partitionFileNames:['dept_default.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink3"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_CUSTOMER_REVIEW_FACT')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "PROJECT_DATAFLOW"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "MEMBER_LOYALTY",
								"type": "DatasetReference"
							},
							"name": "MEMBERLOYALTY"
						},
						{
							"dataset": {
								"referenceName": "CUSTOMER_DIM",
								"type": "DatasetReference"
							},
							"name": "CUSTOMERDIM"
						},
						{
							"dataset": {
								"referenceName": "STORE_LOCATION_DIM",
								"type": "DatasetReference"
							},
							"name": "STORELOACTION"
						},
						{
							"dataset": {
								"referenceName": "DATE_PROJ",
								"type": "DatasetReference"
							},
							"name": "DATEDIM"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "CUST_REVIEW_FACT",
								"type": "DatasetReference"
							},
							"name": "CUSTREVEWFACT"
						}
					],
					"transformations": [
						{
							"name": "join1"
						},
						{
							"name": "join2"
						},
						{
							"name": "join3"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          MEMBER_ID as integer,",
						"          ORDER_DATE as date,",
						"          INITIAL_POINTS_RECEIVED_DATE as date,",
						"          INITIAL_REWARD_POINTS as short,",
						"          LAST_EARNED_POINTS as integer,",
						"          TOTAL_POINTS_EARNED as integer,",
						"          REMAINING_POINTS as integer,",
						"          IS_ACTIVE as boolean,",
						"          STORE_LOCATION_ID as integer,",
						"          ORDER_ID as integer,",
						"          CUSTOMER_ID as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> MEMBERLOYALTY",
						"source(output(",
						"          CUSTOMER_DIM_KEY as integer,",
						"          CUSTOMER_ID as integer,",
						"          CUSTOMER_FIRST_NAME as string,",
						"          CUSTOMER_LAST_NAME as string,",
						"          IS_LOYAL as string,",
						"          PRIMARY_EMAIL as string,",
						"          SECONDARY_EMAIL as string,",
						"          PRIMARY_PHONE_NUMBER as string,",
						"          SECONDARY_PHONE_NUMBER as string,",
						"          R_Address_Lane1 as string,",
						"          R_Address_Lane_2 as string,",
						"          R_City_Name as string,",
						"          R_State_Name as string,",
						"          R_Country_Name as string,",
						"          R_Zip_Code as string,",
						"          R_Gate_Code as string,",
						"          O_ADDRESS_LANE1 as string,",
						"          O_ADDRESS_LANE2 as string,",
						"          O_CITY_NAME as string,",
						"          O_STATE_NAME as string,",
						"          O_COUNTRY_NAME as string,",
						"          O_ZIP_CODE as string,",
						"          O_GATE_CODE as string,",
						"          JOINING_DATE as date,",
						"          STG_CREATE_DATE as date",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> CUSTOMERDIM",
						"source(output(",
						"          Loc_Dim_Key as integer,",
						"          Store_Location_ID as integer,",
						"          Store_Name as string,",
						"          Store_Address as string,",
						"          Store_Open_Time as string,",
						"          Store_Close_Time as string,",
						"          State_Name as string,",
						"          FLAG as string,",
						"          DM_CREATE_DATE as date",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> STORELOACTION",
						"source(output(",
						"          DATE_KEY as integer,",
						"          DAY_YYYY_MM_DD as string,",
						"          DAY_US_MM_DD_YYYY as date,",
						"          DAY_US_LONG as string,",
						"          DAY_US_M_D_YY as string,",
						"          WEEK_SHORT as string,",
						"          WEEK_NUMBER as short,",
						"          WEEK_LONG as string,",
						"          MONTH_IN_QUARTER_NUMBER as string,",
						"          MONTH_IN_YEAR_SHORT as string,",
						"          MONTH_IN_YEAR_LONG as string,",
						"          WEEK_WK_QTR_YEAR as string,",
						"          WEEK_FROM_TO as string,",
						"          WEEK_STARTING as string,",
						"          WEEK_WK_YEAR_CONT as string,",
						"          WEEK_WK_YEAR as string,",
						"          WEEK_WK_QTR_YEAR_CONT as string,",
						"          DAY_IN_WEEK_SHORT as string,",
						"          DAY_IN_WEEK_NUMBER as short,",
						"          DAY_IN_WEEK_LONG as string,",
						"          MONTH_SHORT as string,",
						"          MONTH_NUMBER as string,",
						"          MONTH_LONG as string,",
						"          QUARTER_SHORT_US as string,",
						"          YEAR as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> DATEDIM",
						"MEMBERLOYALTY, CUSTOMERDIM join(MEMBERLOYALTY@CUSTOMER_ID == CUSTOMERDIM@CUSTOMER_ID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1, STORELOACTION join(MEMBERLOYALTY@STORE_LOCATION_ID == STORELOACTION@Store_Location_ID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join2",
						"join2, DATEDIM join(ORDER_DATE == DAY_US_MM_DD_YYYY,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join3",
						"join3 derive(DIM_CREATE_DATE = currentDate()) ~> derivedColumn1",
						"derivedColumn1 select(mapColumn(",
						"          MEMBER_ID,",
						"          TOTAL_POINTS_EARNED,",
						"          REMAINING_POINTS,",
						"          IS_ACTIVE,",
						"          STORE_LOCATION_ID = MEMBERLOYALTY@STORE_LOCATION_ID,",
						"          CUSTOMER_DIM_KEY,",
						"          DATE_KEY,",
						"          DIM_CREATE_DATE",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['CUSTOMER_REVIEW_FACT.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> CUSTREVEWFACT"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_CUSTOMER_STG')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "PROJECT_DATAFLOW"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "PROJECT_STG",
								"type": "DatasetReference"
							},
							"name": "STGCUSTOMERS"
						},
						{
							"dataset": {
								"referenceName": "CUST_ADD",
								"type": "DatasetReference"
							},
							"name": "CUSTOMERADDRESS"
						},
						{
							"dataset": {
								"referenceName": "CUST_EMAIL",
								"type": "DatasetReference"
							},
							"name": "CUSTEMAIL"
						},
						{
							"dataset": {
								"referenceName": "CUST_PHONE",
								"type": "DatasetReference"
							},
							"name": "CUSTPHONE"
						},
						{
							"dataset": {
								"referenceName": "HUT_LOVER",
								"type": "DatasetReference"
							},
							"name": "HUTLOVER"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable_STG_CUSTOMER_JOINS",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "join1"
						},
						{
							"name": "window1"
						},
						{
							"name": "filter1"
						},
						{
							"name": "window2"
						},
						{
							"name": "filter2"
						},
						{
							"name": "window3"
						},
						{
							"name": "filter3"
						},
						{
							"name": "join2"
						},
						{
							"name": "join3"
						},
						{
							"name": "join4"
						},
						{
							"name": "select1"
						},
						{
							"name": "filter4"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "derivedColumn2"
						},
						{
							"name": "surrogateKey1"
						},
						{
							"name": "select2"
						}
					],
					"scriptLines": [
						"source(output(",
						"          CUSTOMER_ID as short,",
						"          CUSTOMER_FIRST_NAME as string,",
						"          CUSTOMER_LAST_NAME as string,",
						"          CUSTOMER_DOB as string,",
						"          CUSTOMER_TYPE as string,",
						"          IS_LOYAL as boolean,",
						"          FIRST_PURCHASE_DATE as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> STGCUSTOMERS",
						"source(output(",
						"          Customer_Address_ID as short,",
						"          Address_Lane1 as string,",
						"          Address_Lane_2 as string,",
						"          City_Name as string,",
						"          State_Name as string,",
						"          Country_Name as string,",
						"          Zip_Code as integer,",
						"          Gate_Code as short,",
						"          Address_Type as string,",
						"          Address_Status as string,",
						"          Customer_ID as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> CUSTOMERADDRESS",
						"source(output(",
						"          CUSTOMER_EMAIL_ID as string,",
						"          CUSTOMER_EMAIL as string,",
						"          CUSTOMER_EMAIL_TYPE as string,",
						"          CUSTOMER_EMAIL_STATUS as string,",
						"          CUSTOMER_ID as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> CUSTEMAIL",
						"source(output(",
						"          CUSTOMER_PHONE_NUMBER_ID as string,",
						"          CUSTOMER_PHONE_NUMBER as string,",
						"          CUSTOMER_PHONE_TYPE as string,",
						"          CUSTOMER_PHONE_STATUS as string,",
						"          CUSTOMER_ID as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> CUSTPHONE",
						"source(output(",
						"          HUT_LOVERS_ID as string,",
						"          JOINING_DATE as string,",
						"          IS_ACTIVE as string,",
						"          MEMBER_ID as string,",
						"          CUSTMOER_ID as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> HUTLOVER",
						"STGCUSTOMERS, derivedColumn1 join(STGCUSTOMERS@CUSTOMER_ID == CUSTOMERADDRESS@Customer_ID,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"CUSTPHONE window(over(CUSTOMER_ID),",
						"     desc(CUSTOMER_PHONE_TYPE, true),",
						"     SECONDARY_PHONE_NUMBER = lead(CUSTOMER_PHONE_NUMBER),",
						"          RN_PH = rowNumber()) ~> window1",
						"window1 filter(RN_PH==1) ~> filter1",
						"CUSTEMAIL window(over(CUSTOMER_ID),",
						"     asc(CUSTOMER_EMAIL_TYPE, true),",
						"     SECONDARY_EMAIL = lead(CUSTOMER_EMAIL),",
						"          RN_EMAIL = rowNumber()) ~> window2",
						"window2 filter(RN_EMAIL==1) ~> filter2",
						"filter4 window(over(Customer_ID),",
						"     desc(Address_Type, true),",
						"     O_ADDRESS_LANE1 = lead(Address_Lane1),",
						"          O_ADDRESS_LANE2 = lead(Address_Lane_2),",
						"          O_CITY_NAME = lead(City_Name),",
						"          O_STATE_NAME = lead(State_Name),",
						"          O_COUNTRY_NAME = lead(Country_Name),",
						"          O_ZIP_CODE = lead(Zip_Code),",
						"          O_GATE_CODE = lead(Gate_Code),",
						"          RN_ADDRESS = rowNumber(),",
						"     partitionBy('hash', 1)) ~> window3",
						"window3 filter(RN_ADDRESS==1) ~> filter3",
						"join1, filter1 join(STGCUSTOMERS@CUSTOMER_ID == CUSTPHONE@CUSTOMER_ID,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join2",
						"join2, filter2 join(STGCUSTOMERS@CUSTOMER_ID == CUSTEMAIL@CUSTOMER_ID,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join3",
						"join3, HUTLOVER join(STGCUSTOMERS@CUSTOMER_ID == CUSTMOER_ID,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join4",
						"join4 select(mapColumn(",
						"          CUSTOMER_ID = STGCUSTOMERS@CUSTOMER_ID,",
						"          CUSTOMER_FIRST_NAME,",
						"          CUSTOMER_LAST_NAME,",
						"          IS_LOYAL,",
						"          PRIMARY_EMAIL = CUSTOMER_EMAIL,",
						"          SECONDARY_EMAIL,",
						"          PRIMARY_PHONE_NUMBER = CUSTOMER_PHONE_NUMBER,",
						"          SECONDARY_PHONE_NUMBER,",
						"          R_Address_Lane1 = Address_Lane1,",
						"          R_Address_Lane_2 = Address_Lane_2,",
						"          R_City_Name = City_Name,",
						"          R_State_Name = State_Name,",
						"          R_Country_Name = Country_Name,",
						"          R_Zip_Code = Zip_Code,",
						"          R_Gate_Code = Gate_Code,",
						"          O_ADDRESS_LANE1,",
						"          O_ADDRESS_LANE2,",
						"          O_CITY_NAME,",
						"          O_STATE_NAME,",
						"          O_COUNTRY_NAME,",
						"          O_ZIP_CODE,",
						"          O_GATE_CODE,",
						"          JOINING_DATE",
						"     ),",
						"     partitionBy('hash', 1),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"CUSTOMERADDRESS filter(Address_Status=='Active') ~> filter4",
						"filter3 derive(O_ADDRESS_LANE1 = case(Address_Type=='Office', Address_Lane1,O_ADDRESS_LANE1),",
						"          O_ADDRESS_LANE2 = case(Address_Type=='Office', Address_Lane_2,O_ADDRESS_LANE2),",
						"          O_CITY_NAME = case(Address_Type=='Office', City_Name,O_CITY_NAME),",
						"          O_STATE_NAME = case(Address_Type=='Office', State_Name,O_STATE_NAME),",
						"          O_COUNTRY_NAME = case(Address_Type=='Office', Country_Name,O_COUNTRY_NAME),",
						"          O_ZIP_CODE = case(Address_Type=='Office', Zip_Code,O_ZIP_CODE),",
						"          O_GATE_CODE = case(Address_Type=='Office', Gate_Code,O_GATE_CODE),",
						"          Address_Lane1 = case(Address_Type == 'Office','NULL',Address_Lane1),",
						"          Address_Lane_2 = case(Address_Type == 'Office','NULL',Address_Lane_2),",
						"          City_Name = case(Address_Type == 'Office','NULL',City_Name),",
						"          State_Name = case(Address_Type == 'Office','NULL',State_Name),",
						"          Country_Name = case(Address_Type == 'Office','NULL',Country_Name),",
						"          Zip_Code = case(Address_Type == 'Office',0,Zip_Code),",
						"          Gate_Code = case(Address_Type == 'Office',0)) ~> derivedColumn1",
						"surrogateKey1 derive(STG_CREATE_DATE = currentDate()) ~> derivedColumn2",
						"select1 keyGenerate(output(CUSTOMER_DIM_KEY as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"derivedColumn2 select(mapColumn(",
						"          CUSTOMER_DIM_KEY,",
						"          CUSTOMER_ID,",
						"          CUSTOMER_FIRST_NAME,",
						"          CUSTOMER_LAST_NAME,",
						"          IS_LOYAL,",
						"          PRIMARY_EMAIL,",
						"          SECONDARY_EMAIL,",
						"          PRIMARY_PHONE_NUMBER,",
						"          SECONDARY_PHONE_NUMBER,",
						"          R_Address_Lane1,",
						"          R_Address_Lane_2,",
						"          R_City_Name,",
						"          R_State_Name,",
						"          R_Country_Name,",
						"          R_Zip_Code,",
						"          R_Gate_Code,",
						"          O_ADDRESS_LANE1,",
						"          O_ADDRESS_LANE2,",
						"          O_CITY_NAME,",
						"          O_STATE_NAME,",
						"          O_COUNTRY_NAME,",
						"          O_ZIP_CODE,",
						"          O_GATE_CODE,",
						"          JOINING_DATE,",
						"          STG_CREATE_DATE",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select2",
						"select2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     recreate:true,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     partitionBy('hash', 1),",
						"     preCommands: [],",
						"     postCommands: []) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_DELIVERY_METHOD_REF')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "PROJECT_DATAFLOW"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DELIVERY_METHOD",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSql_DELIVERY_REF_SCD1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						},
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          DELIVERY_ID as string,",
						"          DELIVERY_TYPE as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 derive(STG_CREATE_DATE = currentDate()) ~> derivedColumn1",
						"derivedColumn1 alterRow(upsertIf(1==1)) ~> alterRow1",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Delivery_Type_Ref_key as integer,",
						"          Delivery_Type_ID as integer,",
						"          Delivery_Type as string,",
						"          STG_CREATE_DATE as date",
						"     ),",
						"     deletable:false,",
						"     insertable:false,",
						"     updateable:false,",
						"     upsertable:true,",
						"     keys:['Delivery_Type_ID'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          Delivery_Type_ID = DELIVERY_ID,",
						"          Delivery_Type = DELIVERY_TYPE,",
						"          STG_CREATE_DATE",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_DERIVED')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "SRC_DERIVED",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Delimited_derived",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText3",
								"type": "DatasetReference"
							},
							"name": "sink2"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText4",
								"type": "DatasetReference"
							},
							"name": "sink3"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						},
						{
							"name": "split1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source1",
						"source1 derive(COUNTRY_CODE = concat('+',PHONE_NUMBER),",
						"          valid_nvalid_email = iif(substring(EMAIL, -10)=='@gmail.com','valid','invalid'),",
						"     partitionBy('hash', 1)) ~> derivedColumn1",
						"derivedColumn1 split(valid_nvalid_email=='valid',",
						"     valid_nvalid_email=='invalid',",
						"     disjoint: true) ~> split1@(emailvalid, EMAILINVALID, DEFAULT)",
						"split1@emailvalid sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          COUNTRY_ID as string,",
						"          COUNTRY_NAME as string,",
						"          REGION_ID as string",
						"     ),",
						"     partitionFileNames:['vaild_email.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1",
						"split1@DEFAULT sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          COUNTRY_ID as string,",
						"          COUNTRY_NAME as string,",
						"          REGION_ID as string",
						"     ),",
						"     partitionFileNames:['email_invalid.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink2",
						"split1@EMAILINVALID sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          COUNTRY_ID as string,",
						"          COUNTRY_NAME as string,",
						"          REGION_ID as string",
						"     ),",
						"     partitionFileNames:['tgt_emailinvalid.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink3"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_FILENAME_COLUMN')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "ASSIGNMENT_DATAFLOW"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Delimited_DEPT_SRC",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Delimited_TGTDEPT",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "cast1"
						},
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          DEPARTMENT_ID as short,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as short,",
						"          LOCATION_ID as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 cast(output(",
						"          DEPARTMENT_ID as integer,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as integer,",
						"          LOCATION_ID as integer",
						"     ),",
						"     errors: true) ~> cast1",
						"cast1 derive(FILE_NAME = 'DEPARTMENTS.csv') ~> derivedColumn1",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          DEPARTMENT_ID as string,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as string,",
						"          LOCATION_ID as string",
						"     ),",
						"     partitionFileNames:['TGT_DEPT_FILENAME.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_FILTER')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "src_not_parameterized",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "tgt_not_parameterized",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "select1"
						},
						{
							"name": "filter1"
						},
						{
							"name": "cast1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as short,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as timestamp,",
						"          JOB_ID as string,",
						"          SALARY as integer,",
						"          COMMISSION_PCT as double,",
						"          MANAGER_ID as short,",
						"          DEPARTMENT_ID as short,",
						"          SK as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"cast1 select(mapColumn(",
						"          EMPLOYEE_ID,",
						"          FIRST_NAME",
						"     ),",
						"     partitionBy('hash', 1),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 filter(EMPLOYEE_ID==100) ~> filter1",
						"source1 cast(output(",
						"          EMPLOYEE_ID as integer '000'",
						"     ),",
						"     errors: true) ~> cast1",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string,",
						"          SK as string",
						"     ),",
						"     partitionFileNames:['TGT_DATAFLOW_CONTROL.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_HARD_DELETE')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Delimited_EMP_SRC",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlTable_EMP",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable_EMP",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "join1"
						},
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as short,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as double,",
						"          COMMISSION_PCT as double,",
						"          MANAGER_ID as short,",
						"          DEPARTMENT_ID as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          EMPLOYEE_ID as integer,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as decimal(10,2),",
						"          COMMISSION_PCT as decimal(10,2),",
						"          MANAGER_ID as integer,",
						"          DEPARTMENT_ID as integer,",
						"          DEPARTMENT_NAME as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> source2",
						"source1, source2 join(source1@EMPLOYEE_ID == source2@EMPLOYEE_ID,",
						"     joinType:'right',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 alterRow(deleteIf(isNull(source1@EMPLOYEE_ID))) ~> alterRow1",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:true,",
						"     insertable:false,",
						"     updateable:false,",
						"     upsertable:false,",
						"     keys:['EMPLOYEE_ID'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          EMPLOYEE_ID = source2@EMPLOYEE_ID,",
						"          FIRST_NAME = source1@FIRST_NAME,",
						"          LAST_NAME = source1@LAST_NAME,",
						"          EMAIL = source1@EMAIL,",
						"          PHONE_NUMBER = source1@PHONE_NUMBER,",
						"          HIRE_DATE = source1@HIRE_DATE,",
						"          JOB_ID = source1@JOB_ID,",
						"          SALARY = source1@SALARY,",
						"          COMMISSION_PCT = source1@COMMISSION_PCT,",
						"          MANAGER_ID = source1@MANAGER_ID,",
						"          DEPARTMENT_ID = source1@DEPARTMENT_ID",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_JOINS')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "src_not_parameterized",
								"type": "DatasetReference"
							},
							"name": "EMP"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText11",
								"type": "DatasetReference"
							},
							"name": "DEPT"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedText10",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "join1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as short,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as timestamp,",
						"          JOB_ID as string,",
						"          SALARY as double,",
						"          COMMISSION_PCT as double,",
						"          MANAGER_ID as short,",
						"          DEPARTMENT_ID as short,",
						"          SK as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> EMP",
						"source(output(",
						"          DEPARTMENT_ID as integer,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as integer,",
						"          LOCATION_ID as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> DEPT",
						"EMP, DEPT join(EMP@DEPARTMENT_ID == DEPT@DEPARTMENT_ID,",
						"     joinType:'right',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 select(mapColumn(",
						"          EMPLOYEE_ID,",
						"          FIRST_NAME,",
						"          LAST_NAME,",
						"          EMAIL,",
						"          PHONE_NUMBER,",
						"          HIRE_DATE,",
						"          JOB_ID,",
						"          SALARY,",
						"          COMMISSION_PCT,",
						"          MANAGER_ID = EMP@MANAGER_ID,",
						"          DEPARTMENT_ID = EMP@DEPARTMENT_ID,",
						"          DEPARTMENT_ID = DEPT@DEPARTMENT_ID,",
						"          DEPARTMENT_NAME,",
						"          MANAGER_ID = DEPT@MANAGER_ID",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          DEPARTMENT_ID as string,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as string,",
						"          LOCATION_ID as string",
						"     ),",
						"     partitionFileNames:['JOINS_EMP_DEPT.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_JOINS_CUSTOMJOIN')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "src_not_parameterized",
								"type": "DatasetReference"
							},
							"name": "EMP"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText11",
								"type": "DatasetReference"
							},
							"name": "DEPT"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedText10",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "join1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as short,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as timestamp,",
						"          JOB_ID as string,",
						"          SALARY as double,",
						"          COMMISSION_PCT as double,",
						"          MANAGER_ID as short,",
						"          DEPARTMENT_ID as short,",
						"          SK as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> EMP",
						"source(output(",
						"          DEPARTMENT_ID as integer,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as integer,",
						"          LOCATION_ID as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> DEPT",
						"EMP, DEPT join(EMPLOYEE_ID==100,",
						"     joinType:'cross',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 select(mapColumn(",
						"          EMPLOYEE_ID,",
						"          DEPARTMENT_ID = EMP@DEPARTMENT_ID,",
						"          DEPARTMENT_ID = DEPT@DEPARTMENT_ID,",
						"          DEPARTMENT_NAME,",
						"          MANAGER_ID = DEPT@MANAGER_ID",
						"     ),",
						"     partitionBy('hash', 1),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          DEPARTMENT_ID as string,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as string,",
						"          LOCATION_ID as string",
						"     ),",
						"     partitionFileNames:['JOINS_EMP_DEPT.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_JOIN_DEPT_EMP_ASSIGN')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "ASSIGNMENT_DATAFLOW"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Delimited_EMP_SRC",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "Delimited_DEPT_SRC",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Delimited_EMP_TGT",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "cast1"
						},
						{
							"name": "cast2"
						},
						{
							"name": "join1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as short,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as double,",
						"          COMMISSION_PCT as double,",
						"          MANAGER_ID as short,",
						"          DEPARTMENT_ID as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source1",
						"source(output(",
						"          DEPARTMENT_ID as short,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as short,",
						"          LOCATION_ID as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1 cast(output(",
						"          EMPLOYEE_ID as integer,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as decimal(10,2),",
						"          COMMISSION_PCT as decimal(10,2),",
						"          MANAGER_ID as integer,",
						"          DEPARTMENT_ID as integer",
						"     ),",
						"     errors: true) ~> cast1",
						"source2 cast(output(",
						"          DEPARTMENT_ID as integer,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as integer,",
						"          LOCATION_ID as integer",
						"     ),",
						"     errors: true) ~> cast2",
						"cast1, cast2 join(cast1@DEPARTMENT_ID == cast2@DEPARTMENT_ID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 select(mapColumn(",
						"          EMPLOYEE_ID,",
						"          FIRST_NAME,",
						"          LAST_NAME,",
						"          EMAIL,",
						"          PHONE_NUMBER,",
						"          HIRE_DATE,",
						"          JOB_ID,",
						"          SALARY,",
						"          COMMISSION_PCT,",
						"          MANAGER_ID = cast1@MANAGER_ID,",
						"          DEPARTMENT_ID = cast2@DEPARTMENT_ID,",
						"          DEPARTMENT_NAME,",
						"          MANAGER_ID = cast2@MANAGER_ID,",
						"          LOCATION_ID",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          emp_id as string,",
						"          name as string",
						"     ),",
						"     partitionFileNames:['TGT_JOIN_EMP_DEPT_ASSIGN.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_LKP_LOC')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Delimited_EMP_SRC",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText11",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Delimited_EMP_TGT",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "cast1"
						},
						{
							"name": "cast2"
						},
						{
							"name": "lookup1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          LOCATION_ID as short,",
						"          STREET_ADDRESS as string,",
						"          POSTAL_CODE as string,",
						"          CITY as string,",
						"          STATE_PROVINCE as string,",
						"          COUNTRY_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source1",
						"source(output(",
						"          DEPARTMENT_ID as string,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as string,",
						"          LOCATION_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1 cast(output(",
						"          LOCATION_ID as integer,",
						"          STREET_ADDRESS as string,",
						"          POSTAL_CODE as string,",
						"          CITY as string",
						"     ),",
						"     errors: true) ~> cast1",
						"source2 cast(output(",
						"          DEPARTMENT_ID as integer,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as string,",
						"          LOCATION_ID as integer",
						"     ),",
						"     errors: true) ~> cast2",
						"cast1, cast2 lookup(cast1@LOCATION_ID == cast2@LOCATION_ID,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     partitionBy('hash', 1),",
						"     broadcast: 'auto')~> lookup1",
						"lookup1 select(mapColumn(",
						"          LOCATION_ID = cast1@LOCATION_ID,",
						"          STREET_ADDRESS,",
						"          CITY,",
						"          COUNTRY_ID,",
						"          DEPARTMENT_ID,",
						"          DEPARTMENT_NAME",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          emp_id as string,",
						"          name as string",
						"     ),",
						"     partitionFileNames:['LKP_DEPT_LOC.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_LOCATION_DIM')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "PROJECT_DATAFLOW"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable_LOCATION_STG",
								"type": "DatasetReference"
							},
							"name": "locationdimquery"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable_LOCATIONS_DIMSCD",
								"type": "DatasetReference"
							},
							"name": "insert"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlTable_LOCATIONS_DIMSCD",
								"type": "DatasetReference"
							},
							"name": "update"
						}
					],
					"transformations": [
						{
							"name": "filter1"
						},
						{
							"name": "filter2"
						},
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          src_Store_Location_ID as short,",
						"          src_Store_Name as string,",
						"          src_Store_Address as string,",
						"          src_Store_Open_Time as string,",
						"          src_Store_Close_Time as string,",
						"          src_State_Name as string,",
						"          tgt_Store_Location_ID as integer,",
						"          tgt_Store_Name as string,",
						"          tgt_Store_Address as string,",
						"          tgt_Store_Open_Time as string,",
						"          tgt_Store_Close_Time as string,",
						"          tgt_State_Name as string,",
						"          tgt_FLAG as string,",
						"          Loc_Dim_Key as integer,",
						"          DM_CREATE_DATE as date,",
						"          src_md5 as binary,",
						"          tgt_md5 as binary,",
						"          flag_new as string,",
						"          flag_deactivate as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: 'select \\nsrc_Store_Location_ID\\n,src_Store_Name\\n,src_Store_Address\\n,src_Store_Open_Time\\n,src_Store_Close_Time\\n,src_State_Name\\n,tgt_Store_Location_ID\\n,tgt_Store_Name\\n,tgt_Store_Address\\n,tgt_Store_Open_Time\\n,tgt_Store_Close_Time\\n,tgt_State_Name\\n,tgt_FLAG\\n,Loc_Dim_Key\\n,DM_CREATE_DATE\\n,src_md5\\n,tgt_md5\\n,case when tgt_Store_Location_ID is NULL or src_md5 <> tgt_md5 then \\'Y\\' end flag_new\\n,case when tgt_Store_Location_ID is not NULL and src_md5 <> tgt_md5 then \\'N\\' end flag_deactivate\\nfrom ( \\nselect \\nA.Store_Location_ID as src_Store_Location_ID,\\nA.Store_Name as src_Store_Name,\\nA.Store_Address as src_Store_Address,\\nA.Store_Open_Time as src_Store_Open_Time,\\nA.Store_Close_Time as src_Store_Close_Time,\\nA.State_Name as src_State_Name,\\nB.Store_Location_ID as tgt_Store_Location_ID,\\nB.Store_Name as tgt_Store_Name,\\nB.Store_Address as tgt_Store_Address,\\nB.Store_Open_Time as tgt_Store_Open_Time,\\nB.Store_Close_Time as tgt_Store_Close_Time,\\nB.State_Name as tgt_State_Name,\\nB.FLAG as tgt_FLAG,\\nB.Loc_Dim_Key,\\ncast(getdate() as date) as DM_CREATE_DATE,\\nHashBytes(\\'MD5\\',concat(cast(A.Store_Name as varchar),cast(A.Store_Address as varchar),cast(A.Store_Open_Time as varchar),cast(A.Store_Close_Time as varchar),cast(A.State_Name as varchar))) as src_md5,\\nHashBytes(\\'MD5\\',concat(cast(B.Store_Name as varchar),cast(B.Store_Address as varchar),cast(B.Store_Open_Time as varchar),cast(B.Store_Close_Time as varchar),cast(B.State_Name as varchar))) as tgt_md5\\nfrom HR.locations_dim A \\nleft Join HR.location_dim1 B on \\nA.Store_Location_ID = B.Store_Location_ID\\nand B.FLAG = \\'Y\\'\\n)a',",
						"     format: 'query') ~> locationdimquery",
						"locationdimquery filter(isNull(tgt_Store_Location_ID) || src_md5 != tgt_md5) ~> filter1",
						"locationdimquery filter(!isNull(tgt_Store_Location_ID) && src_md5 != tgt_md5) ~> filter2",
						"filter2 alterRow(updateIf(1==1)) ~> alterRow1",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          Store_Location_ID = src_Store_Location_ID,",
						"          Store_Name = src_Store_Name,",
						"          Store_Address = src_Store_Address,",
						"          Store_Open_Time = src_Store_Open_Time,",
						"          Store_Close_Time = src_Store_Close_Time,",
						"          State_Name = src_State_Name,",
						"          DM_CREATE_DATE,",
						"          FLAG = flag_new",
						"     )) ~> insert",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:false,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['Loc_Dim_Key'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          Loc_Dim_Key,",
						"          FLAG = flag_deactivate",
						"     )) ~> update"
					]
				}
			},
			"dependsOn": []
		}
	]
}